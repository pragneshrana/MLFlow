{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragneshrana/MLFlow/blob/main/LLM/LangChainRetrivalPineCone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gELj3m3eP9nP"
      },
      "outputs": [],
      "source": [
        "! pip install -qU \\\n",
        "  pinecone-client==3.0.0 \\\n",
        "  pinecone-datasets==0.7.0 \\\n",
        "  langchain-pinecone==0.0.3 \\\n",
        "  langchain-openai==0.0.7 \\\n",
        "  langchain==0.1.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fT635-ZNRNBa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "pinecone_api_key = ''\n",
        "# openai_api_key = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5VFJEQ3ZXdM"
      },
      "source": [
        "### Loading sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QiCbXy6lRuBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254cf55c-932e-421f-a548-eecd352bc365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pinecone_datasets\n",
        "\n",
        "dataset = pinecone_datasets.load_dataset('wikipedia-simple-text-embedding-ada-002-100K')\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xY8XGu8sRuVr"
      },
      "outputs": [],
      "source": [
        "# we drop sparse_values as they are not needed for this example\n",
        "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
        "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
        "# we will use rows of the dataset up to index 30000\n",
        "dataset.documents.drop(dataset.documents.index[300:], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THPXbmTNZacp"
      },
      "source": [
        "### Setting Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9xQwGpQsR8em"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
        "import time\n",
        "\n",
        "use_serverless = False\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "if use_serverless:\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-west-2')\n",
        "else:\n",
        "    # if not using a starter index, you should specify a pod_type too\n",
        "    spec = PodSpec(\n",
        "    environment=\"gcp-starter\"\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fGtScbIgSG6K"
      },
      "outputs": [],
      "source": [
        "# check for and delete index if already exists\n",
        "index_name = 'testing'\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "# create a new index\n",
        "pc.create_index(\n",
        "    index_name,\n",
        "    dimension=1536,  # dimensionality of text-embedding-ada-002\n",
        "    metric='dotproduct',\n",
        "    spec=spec\n",
        ")\n",
        "\n",
        "# wait for index to be initialized\n",
        "while not pc.describe_index(index_name).status['ready']:\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DM0zvx-UVbtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e622b4-15a0-43c8-d984-cf6fb46e6257"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "index = pc.Index(index_name)\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a458QqIOZgnp"
      },
      "source": [
        "### Adding embeding to pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cjMUQOwyW7Ss"
      },
      "outputs": [],
      "source": [
        "#adding data\n",
        "for batch in dataset.iter_documents(batch_size=4):\n",
        "    index.upsert(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0EDWFRpqW_5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b101b594-d71a-4d23-d00b-906ac36d1c5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9wO0g5kz6L"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/modules/data_connection/text_embedding/\n",
        "\n",
        "\n",
        "https://bakshiharsh55.medium.com/text-embedding-models-in-langchain-887f1873c7ac"
      ],
      "metadata": {
        "id": "WkTqB_AqAwGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import FakeEmbeddings\n",
        "embeddings = FakeEmbeddings(size=1536)"
      ],
      "metadata": {
        "id": "1Mhkvup8niNN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "text_field = \"text\"\n",
        "\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index, embeddings, text_field\n",
        ")"
      ],
      "metadata": {
        "id": "9yjqMMzJD0ZT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is particle?\"\n",
        "\n",
        "vectorstore.similarity_search(\n",
        "    query,  # our search query\n",
        "    k=3  # return 3 most relevant docs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9iHvkpKxwD-",
        "outputId": "6a9dda26-1e4e-4a29-a19c-ca89e479b534"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Further into the 20th century, physicists went deeper into the mysteries of the atom. Using particle accelerators they discovered that protons and neutrons were actually made of other particles, called quarks.\\n\\nThe most accurate model so far comes from the Schrödinger equation. Schrödinger realized that the electrons exist in a cloud around the nucleus, called the electron cloud. In the electron cloud, it is impossible to know exactly where electrons are. The Schrödinger equation is used to find out where an electron is likely to be. This area is called the electron's orbital.\\n\\nStructure and parts\\n\\nParts \\nThe complex atom is made up of three main particles; the proton, the neutron and the electron. The isotope of Hydrogen Hydrogen-1 has no neutrons, just the one proton and one electron. Protons have a positive electric charge and electrons have a negative charge.  A positive hydrogen ion has no electrons, just the one proton.  These two examples are the only known exceptions to the rule that all other atoms have at least one proton, one neutron and one electron each.\", metadata={'chunk': 5.0, 'source': 'https://simple.wikipedia.org/wiki/Atom', 'title': 'Atom', 'wiki-id': '47'}),\n",
              " Document(page_content='High-scale computers \\nScientists figured out how to make and use digital computers in the 1930s to 1940s. Scientists made a lot of digital computers, and as they did, they figured out how to ask them the right sorts of questions to get the most out of them. Here are a few of the computers they built:\\n\\n Konrad Zuse\\'s electromechanical \"Z machines\". The Z3 (1941) was the first working machine that used binary arithmetic. Binary arithmetic means using \"Yes\" and \"No.\" to add numbers together. You could also program it. In 1998 the Z3 was proved to be Turing complete. Turing complete means that it is possible to tell this particular computer anything that it is mathematically possible to tell a computer. It is the world\\'s first modern computer.\\n The non-programmable Atanasoff–Berry Computer (1941) which used vacuum tubes to store \"yes\" and \"no\" answers, and regenerative capacitor memory.\\n The Harvard Mark I (1944), A big computer that you could kind of program.\\n The U.S. Army\\'s Ballistics Research Laboratory ENIAC (1946), which could add numbers the way people do (using the numbers 0 through 9) and is sometimes called the first general purpose electronic computer (since Konrad Zuse\\'s Z3 of 1941 used electromagnets instead of electronics). At first, however, the only way to reprogram ENIAC was by rewiring it.', metadata={'chunk': 5.0, 'source': 'https://simple.wikipedia.org/wiki/Computer', 'title': 'Computer', 'wiki-id': '112'}),\n",
              " Document(page_content=\"Geography \\n\\nBelgium is next to France, Germany, Luxembourg and the Netherlands. Its total area is 33,990 square kilometers. The land area alone is 30,528\\xa0km². Belgium has three main geographical regions. The coastal plain is in the north-west. The central plateau are part of the Anglo-Belgian Basin. The Ardennes uplands are in the south-east. The Paris Basin reaches a small fourth area at Belgium's southernmost tip, Belgian Lorraine.\\n\\nThe coastal plain is mostly sand dunes and polders. Further inland is a smooth, slowly rising landscape. There are fertile valleys. The hills have many forests. The plateaus of the Ardennes are more rough and rocky. They have caves and small, narrow valleys. Signal de Botrange is the country's highest point at 694 metres (2,277\\xa0ft).\\n\\nProvinces\\nBelgium is divided into three Regions.  Flanders and Wallonia are divided into provinces. The third Region, Brussels is not part of any province.\\n\\nMilitary\\nThe Belgian Armed Forces have about 46,000 active troops. In 2009 the yearly defence budget was $6 billion. There are four parts: Belgian Land Component, or the Army; Belgian Air Component, or the Air Force; Belgian Naval Component, or the Navy; Belgian Medical Component.\\n\\nScience and technology\\n\\nAdding to science and technology has happened throughout the country's history. cartographer Gerardus Mercator, anatomist Andreas Vesalius, herbalist Rembert Dodoens and mathematician Simon Stevin are among the most influential scientists.\", metadata={'chunk': 3.0, 'source': 'https://simple.wikipedia.org/wiki/Belgium', 'title': 'Belgium', 'wiki-id': '103'})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUej3fINAiCn"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0IsDbSByH2svlSzu7NRJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}